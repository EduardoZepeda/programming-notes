## 1.16 Servicios

Los servicios son una abstracción para el acceso a un conjunto de pods que
implementan un microservicio (backend, frontend, etc.). Ofrecen una dirección
virtual y un nombre que identifica al conjunto de pods que representan.

Se diferencian de los deployments en que el primero se encarga de mantener un
grupo de pods funcionando, mientras que un servicio se encarga de otorgar acceso
de red a un conjunto de pods.

La conexión a un servicio se puede realizar desde otros pods o desde el
exterior.

Se implementan con iptables y son monitoreados por el componente kube-proxy.

Cuando se crea un nuevo servicio, se le asigna una nueva ip interna virtual
(IP-CLUSTER) que permite la conexión desde otros pods.

### 1.16.1 Tipos de servicios

-   ClusterIP: Reserva una IP virtual fija para el servicio que elijamos. Solo
    permite el acceso interno entre distintos servicios. Es el tipo por defecto.
    Podemos acceder desde el exterior con la instrucción *kubectl proxy*
-   NodePort: Un puerto para el servicio en cada uno los nodos, generalmente en
    el rango de 30000 a 40000. Que nos permitirá acceder interna o externamente
    a partir de la ip del servidor master del cluster.
-   LoadBalancer: Balanceador externo provisionado para cloud providers (GKE,
    AKS o AWS).
-   ExternalName: Entrada de DNS que es gestionada por CoreDNS.

### 1.16.2 Creación de un servicio Cluster IP

Para crear un servicio, podemos establecer la definición del recurso en un
archivo yml:

``` yml
apiVersion: v1
kind: Service
metadata:
name: nginx
namespace: default
spec:
  type: ClusterIP
  ports:
  - name: http
      port: 80
      targetPort: http
      # targerPort: 80 también es válido
  selector:
      app: nginx
      #role: hello
```

selector especifica los pods a los que se les otorgará acceso. Además de por
App, podriamos establecer un selector por rol, a partir de un deployment

``` yml
kind: Deployment
# ...
spec:
  #...
  matchLabels:
    role: hello
    template:
      metadata:
        labels:
          role: hello
```

Una manera alternative sería:

```bash
kubectl expose deployment/nginx --port=80 --type=ClusterIP
```

### 1.16.3 Acceso a un ClusterIP

Para acceder desde el exterior podemos usar kubectl proxy.

```bash
kubectl proxy [--port=<numero>]
```

Y nos dejará el acceso libre en la dirección:

```bash
http://localhost:8001/api/v1/namespaces/<NAMESPACE>/services/<SERVICE NAME>:<PORT NAME>/proxy/
# PORT_NAME = HTTP
```

### 1.16.4 Creación de un servicio Node Port

Para establecer el tipo nodePort lo podemos hacer directamente en el servicio, estableciendo el tipo y el nodePort. Este tipo tiene el inconveniente de que se necesita conocer la dirección IP de cada nodo para acceder a él.

``` yml
apiVersion: v1
kind: Service
metadata:
name: nginx
namespace: default
spec:
  type: NodePort
  ports:
  - name: http
      port: 80
      targetPort: 8080
      nodePort: 30000
  selector:
      app: nginx
      #role: hello
```

Tras hacerlo y realizar un kubectl get all

```bash
kubectl get nodes
NAME             TYPE
service/hello   NodePort
```

Tras esto podemos hacer un curl a la IP externa de nuestros nodos en el puerto que especificamos y deberiamos recibir una respuesta

```bash
kubectl get nodes - o wide
NAME             EXTERNAL-IP
pool-123          143.244.166.129

curl 143.244.166.129:30000
# Response
```

### 1.16.5 Acceso con kubectl-post-forward

Esto nos permite realizar lo mismo que kubectl-proxy, pero accediendo a
cualquier puerto del servicio expuesto en nuestro cluster

```bash
kubectl post-foward svc/<svc> <puerto_local>:<puerto_remoto> &
```

### 1.16.6 Acceso a NodePort

Si modificamos el type del archivo anterior

```bash
type: NodePort
```

Tendriamos acceso al servicio a partir de la dirección IP del cluster y el
puerto asignado.

```bash
kubectl get svc
NAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
nginx        NodePort    <IP>             <none>        80:34325/TCP   3h
```

### 1.16.7 Ejemplo de deployment

Para este ejemplo creamos primero un deployment de una imagen

```bash
kubectl create deployment httpenv --image jpetazzo/httpenv
```

A continuación escalamos una aplicación para crear múltiples pods con scale,
esto nos dejará con 10 pods.

```bash
kubectl scale deployment httpenv --replicas=10
```

Ahora exponemos nuestro deployment y sus pods como un servicio

```bash
kubectl expose deployment <httpenv> --port=8888
```

Estará disponible como servicio y podremos verlo con el comando get svc
(servicios)

```bash
kubectl get svc
NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE
httpenv      ClusterIP   10.96.204.73   <none>        8888/TCP   100s
kubernetes   ClusterIP   10.96.0.1      <none>        443/TCP    44m
```

Ahora si hacemos un curl, múltiples veces a esta dirección, podremos recuperar
las variables de entorno y apreciaremos un HOSTNAME diferente cada vez, lo que
indica que el balanceador de carga está funcionando.

```bash
curl http://10.96.204.73:8888 | jq ""
{
    "HOME": "/root",
    "HOSTNAME": "httpenv-57b8868f99-dqx52",
}
```

Podemos obtener las reglas de enrutado para el OUTPUT

```bash
sudo iptables -t nat -L OUTPUT
sudo iptables -t nat -nL KUBE-SERVICES
```

El administrador de todas las reglas es *kube-proxy*. Podemos buscar la IP de
nuestro servicio

Y eso nos dará la lista de servicios. Si, ahora obtenemos las reglas de ese
servicio

```bash
sudo iptables -t nat -nL KUBE-SVC-<ID>
```

Por defecto maneja una probabilidad azaroza (random probability), de 0 a 1, con
una diferente ponderación para cada pod.

Del output anterior buscamos el que querramos conocer y lo usamos para ver a
donde se dirige el tráfico, es decir a la **ip interna privada** de nuestro
nodo.

```bash
sudo iptables -t nat -nL KUBE-SEP-<ID>
```

